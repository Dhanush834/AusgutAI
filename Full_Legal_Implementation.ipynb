{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush834/AusgutAI/blob/main/Full_Legal_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6jseLEgVhC3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai portkey-ai transformers torch sentence-transformers scikit-learn numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054Rd2MfOxzg",
        "outputId": "480388a3-76a7-42fe-bf51-6c66abead176"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.44.0)\n",
            "Requirement already satisfied: portkey-ai in /usr/local/lib/python3.10/dist-packages (1.8.7)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: mypy<2.0,>=0.991 in /usr/local/lib/python3.10/dist-packages (from portkey-ai) (1.11.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.10/dist-packages (from portkey-ai) (1.5.2)\n",
            "Requirement already satisfied: types-requests in /usr/local/lib/python3.10/dist-packages (from portkey-ai) (2.32.0.20240907)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from mypy<2.0,>=0.991->portkey-ai) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy<2.0,>=0.991->portkey-ai) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yj8Y2fqGzZwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class IndianLawRAGAgent:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def answer_legal_question(self, question, context):\n",
        "        inputs = self.bert_tokenizer(question, context, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(**inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_legal_advice(self, startup_type, situation):\n",
        "        relevant_docs = self.retrieve_relevant_documents(f\"{startup_type} {situation}\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"As a legal expert, provide advice for an Indian {startup_type} startup in the following situation: {situation}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Advice:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian startup law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize_law(self, law_name):\n",
        "        relevant_docs = self.retrieve_relevant_documents(law_name)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Summarize the key points of the Indian law: {law_name}, especially as it pertains to startups.\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian law summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def check_compliance(self, startup_description):\n",
        "        relevant_docs = self.retrieve_relevant_documents(startup_description)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Given the following Indian startup description, list the key compliance requirements and potential legal issues to be aware of: {startup_description}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance requirements and potential legal issues:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in compliance for Indian startups.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "def main():\n",
        "    agent = IndianLawRAGAgent(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Answer a legal question\")\n",
        "    print(\"2. Generate legal advice\")\n",
        "    print(\"3. Summarize a law\")\n",
        "    print(\"4. Check compliance requirements\")\n",
        "\n",
        "    choice = int(input(\"Enter the number of your choice: \"))\n",
        "\n",
        "    if choice == 1:\n",
        "        legal_question = input(\"Enter your legal question: \")\n",
        "        legal_context = input(\"Enter the legal context: \")\n",
        "        answer = agent.answer_legal_question(legal_question, legal_context)\n",
        "        print(f\"Answer: {answer}\")\n",
        "\n",
        "    elif choice == 2:\n",
        "        startup_type = input(\"Enter the startup type: \")\n",
        "        situation = input(\"Describe the situation: \")\n",
        "        advice = agent.generate_legal_advice(startup_type, situation)\n",
        "        print(f\"Legal Advice: {advice}\")\n",
        "\n",
        "    elif choice == 3:\n",
        "        law_name = input(\"Enter the law name: \")\n",
        "        summary = agent.summarize_law(law_name)\n",
        "        print(f\"Law Summary: {summary}\")\n",
        "\n",
        "    elif choice == 4:\n",
        "        startup_description = input(\"Enter the startup description: \")\n",
        "        compliance = agent.check_compliance(startup_description)\n",
        "        print(f\"Compliance Check: {compliance}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "alD8NUb3-uMJ",
        "outputId": "9be45b21-6be2-4d54-f3a2-57086045e0da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choose an option:\n",
            "1. Answer a legal question\n",
            "2. Generate legal advice\n",
            "3. Summarize a law\n",
            "4. Check compliance requirements\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-577297a29a7a>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-577297a29a7a>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"4. Check compliance requirements\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mchoice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the number of your choice: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchoice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class IndianLawRAGAgent:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def answer_legal_question(self, question, context):\n",
        "        inputs = self.bert_tokenizer(question, context, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_legal_advice(self, startup_type, situation):\n",
        "        relevant_docs = self.retrieve_relevant_documents(f\"{startup_type} {situation}\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"As a legal expert, provide advice for an Indian {startup_type} startup in the following situation: {situation}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Advice:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian startup law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize_law(self, law_name):\n",
        "        relevant_docs = self.retrieve_relevant_documents(law_name)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Summarize the key points of the Indian law: {law_name}, especially as it pertains to startups.\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian law summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def check_compliance(self, startup_description):\n",
        "        relevant_docs = self.retrieve_relevant_documents(startup_description)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Given the following Indian startup description, list the key compliance requirements and potential legal issues to be aware of: {startup_description}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance requirements and potential legal issues:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in compliance for Indian startups.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def handle_user_input(self, user_input):\n",
        "        # Step 1: Summarize the user input\n",
        "        summarization_prompt = f\"\"\"Summarize the following legal input to extract key points:\n",
        "\n",
        "        Input: {user_input}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        summarization_response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI summarization assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": summarization_prompt}\n",
        "            ]\n",
        "        )\n",
        "        summarized_input = summarization_response.choices[0].message.content.strip()\n",
        "        print(f\"Summarized Input: {summarized_input}\")\n",
        "\n",
        "        # Step 2: Classify the user input into a type (e.g., 'legal question', 'generate advice', etc.)\n",
        "        classification_prompt = f\"\"\"Classify the following summarized legal input into one of these categories:\n",
        "        'legal question', 'generate advice', 'summarize law', 'check compliance'.\n",
        "\n",
        "        Summary: {summarized_input}\n",
        "\n",
        "        Classification:\"\"\"\n",
        "\n",
        "        classification_response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI classification assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": classification_prompt}\n",
        "            ]\n",
        "        )\n",
        "        classification = classification_response.choices[0].message.content.strip().lower()\n",
        "        print(f\"Classification: {classification}\")\n",
        "\n",
        "        # Step 3: Based on classification, automatically generate the legal context or invoke appropriate function\n",
        "        if \"legal question\" in classification:\n",
        "            # Use OpenAI to generate the legal context automatically\n",
        "            legal_context_prompt = f\"\"\"Generate the legal context for the following legal question:\n",
        "\n",
        "            Question: {summarized_input}\n",
        "\n",
        "            Legal Context:\"\"\"\n",
        "\n",
        "            legal_context_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an AI legal context assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": legal_context_prompt}\n",
        "                ]\n",
        "            )\n",
        "            legal_context = legal_context_response.choices[0].message.content.strip()\n",
        "            print(f\"Legal Context: {legal_context}\")\n",
        "            return f\"Function called: answer_legal_question\\nResponse: {self.answer_legal_question(summarized_input, legal_context)}\"\n",
        "\n",
        "        elif \"generate advice\" in classification:\n",
        "            # Auto-generate startup type based on the input (if applicable)\n",
        "            startup_type_prompt = f\"\"\"Identify the startup type based on the following input:\n",
        "\n",
        "            Input: {summarized_input}\n",
        "\n",
        "            Startup Type:\"\"\"\n",
        "\n",
        "            startup_type_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an AI startup classification assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": startup_type_prompt}\n",
        "                ]\n",
        "            )\n",
        "            startup_type = startup_type_response.choices[0].message.content.strip()\n",
        "            print(f\"Startup Type: {startup_type}\")\n",
        "            return f\"Function called: generate_legal_advice\\nResponse: {self.generate_legal_advice(startup_type, summarized_input)}\"\n",
        "\n",
        "        elif \"summarize law\" in classification:\n",
        "            return f\"Function called: summarize_law\\nResponse: {self.summarize_law(summarized_input)}\"\n",
        "\n",
        "        elif \"check compliance\" in classification:\n",
        "            return f\"Function called: check_compliance\\nResponse: {self.check_compliance(summarized_input)}\"\n",
        "\n",
        "        else:\n",
        "            return \"Sorry, I couldn't classify your input. Please try again.\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    agent = IndianLawRAGAgent(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    response = agent.handle_user_input(user_input)\n",
        "    print(f\"Response: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9yLbuIrioLaX",
        "outputId": "b1965fbe-ef9d-4b15-803e-676a7d622680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your request: startup in cyber tech\n",
            "Summarized Input: Summary: A startup in cyber tech refers to a new business venture that focuses on developing technology related to cybersecurity. This involves creating innovative solutions to protect digital systems, networks, data, and programs from attacks, damages, or unauthorized access.\n",
            "Classification: the provided summary does not present a legal question, seek specific advice, or check compliance. rather, it describes what a cyber tech startup is. this aligns best with 'summarize law' as it is summarizing the focus and activities of businesses in a specific sector, albeit without explicitly mentioning legal frameworks. \n",
            "\n",
            "classification: 'summarize law'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (776 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Legal Context: In considering the legal context for a startup in the cyber tech industry, particularly one that focuses on cybersecurity, several areas of law come into play. This legal framework is crucial to ensure that the startup not only protects itself from legal pitfalls but also operates in compliance with various statutes and regulations that govern data protection, intellectual property, contractual relationships, and liability issues. Here are the key areas of law relevant to a cybersecurity startup:\n",
            "\n",
            "1. **Cybersecurity Laws and Regulations**: A cybersecurity startup must adhere to legal standards and frameworks that govern the storage, processing, and transmission of data. For example, in the United States, regulations such as the General Data Protection Regulation (GDPR) in Europe and the California Consumer Privacy Act (CCPA) in California impose strict requirements on the handling of personal data. These laws also define the duties of cybersecurity providers, including breach notification requirements and compliance obligations.\n",
            "\n",
            "2. **Intellectual Property (IP) Rights**: Protecting intellectual property is crucial for startups, particularly in technology-intensive sectors like cybersecurity. This includes securing patents for any new technology or processes, trademarking the company branding, and copyrighting software code or any written materials. Proper IP management ensures that the startup’s innovations are protected from unauthorized use or infringement, and also enhances the company’s valuation and appeal to both investors and clients.\n",
            "\n",
            "3. **Contracts and Agreements**: Various forms of contracts are fundamental in the cybersecurity field, including licensing agreements, service level agreements (SLAs), non-disclosure agreements (NDAs), and employment contracts. These documents must be crafted to clearly define the rights and obligations of all parties, ensuring clarity over the provision of services, confidentiality of data, and the terms of employment.\n",
            "\n",
            "4. **Liability and Risk Management**: Understanding and managing potential liabilities associated with providing cybersecurity services is vital. This involves setting clear terms regarding the extent and limitations of liability in contracts, obtaining appropriate insurance (e.g., errors and omissions insurance), and establishing protocols to minimize the risk of security breaches or failures in provided services.\n",
            "\n",
            "5. **Compliance with National Security Laws**: In some jurisdictions, cybersecurity is linked with national security. Startups in the cybersecurity domain may be required to comply with specific national security laws—especially when dealing with government contracts or sensitive industries. This may include limitations on foreign ownership or control, as well as adherence to export control laws if the technology is shared across borders.\n",
            "\n",
            "6. **Privacy Laws**: Since cybersecurity companies often handle sensitive data, compliance with privacy laws is essential. This includes implementing robust measures to protect privacy as per regulatory requirements, maintaining transparency about data collection and use, and ensuring that the technology used adheres to the principle of privacy by design.\n",
            "\n",
            "7. **Employment Law**: A cybersecurity startup must also adhere to employment laws, which govern hiring practices, employee rights, workplace conditions, and termination procedures. Particularly in tech industries, considerations around intellectual property rights in employment contracts and the use of non-compete clauses are vital.\n",
            "\n",
            "Navigating the legal landscape requires a multifaceted approach, often demanding ongoing legal consultation and a proactive stance on regulatory changes in the cybersecurity arena. It is advisable for startups to engage with legal professionals who specialize in the areas of technology and cybersecurity to ensure full compliance and to protect the enterprise from potential legal challenges.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not tuple",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-30eced63d0d5>\u001b[0m in \u001b[0;36m<cell line: 208>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-30eced63d0d5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter your request: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Response: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-30eced63d0d5>\u001b[0m in \u001b[0;36mhandle_user_input\u001b[0;34m(self, user_input)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlegal_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegal_context_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Legal Context: {legal_context}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"Function called: answer_legal_question\\nResponse: {self.answer_legal_question(summarized_input, legal_context)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"generate advice\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-30eced63d0d5>\u001b[0m in \u001b[0;36manswer_legal_question\u001b[0;34m(self, question, context)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0manswer_legal_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0manswer_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, start_positions, end_positions, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1975\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1978\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4688\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4689\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4690\u001b[0m             warn_string = (\n\u001b[1;32m   4691\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "id": "ggqsQz6PDUjR",
        "outputId": "328a362d-0a50-43d7-ff1a-b65ff33a09a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m225.3/244.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KIeSzcmoEJ-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from docx import Document\n",
        "\n",
        "class ContractGenerator:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def extract_information_with_bert(self, text):\n",
        "        inputs = self.bert_tokenizer(text, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(**inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_contract(self, details):\n",
        "        # Use BERT to extract and refine contract details if necessary\n",
        "        refined_details = self.extract_information_with_bert(details)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Create a legal contract based on the following details:\n",
        "\n",
        "        Contract Details:\n",
        "        {refined_details}\n",
        "\n",
        "        The contract should include:\n",
        "        - Names of the parties\n",
        "        - Effective date\n",
        "        - Terms and conditions\n",
        "        - Signatures\n",
        "\n",
        "        Contract:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a legal expert specializing in drafting contracts.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def save_contract_to_file(self, contract_text, filename=\"contract.docx\"):\n",
        "        doc = Document()\n",
        "        doc.add_paragraph(contract_text)\n",
        "        doc.add_paragraph(\"[It is advisable that both parties have this document reviewed by their respective legal advisors before signing.]\")\n",
        "        doc.save(filename)\n",
        "\n",
        "    def handle_user_request(self, contract_details):\n",
        "        # Generate contract text\n",
        "        contract_text = self.generate_contract(contract_details)\n",
        "        print(f\"Generated Contract: {contract_text}\")\n",
        "\n",
        "        # Save to file\n",
        "        filename = \"generated_contract.docx\"\n",
        "        self.save_contract_to_file(contract_text, filename)\n",
        "\n",
        "        return filename\n",
        "\n",
        "def main():\n",
        "    agent = ContractGenerator(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    # Collect contract details from the user\n",
        "    print(\"Please provide the following details for the contract:\")\n",
        "    party1 = input(\"Party 1: \")\n",
        "    party2 = input(\"Party 2: \")\n",
        "    effective_date = input(\"Effective Date (YYYY-MM-DD): \")\n",
        "    terms = input(\"Terms and Conditions: \")\n",
        "\n",
        "    contract_details = f\"\"\"\n",
        "    Party 1: {party1}\n",
        "    Party 2: {party2}\n",
        "    Effective Date: {effective_date}\n",
        "    Terms and Conditions: {terms}\n",
        "    \"\"\"\n",
        "\n",
        "    filename = agent.handle_user_request(contract_details)\n",
        "    print(f\"Contract has been generated and saved as {filename}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "nPySUAVk3pql",
        "outputId": "49ecbfaa-7776-4612-a99b-5fddedea3430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide the following details for the contract:\n",
            "Party 1: frere\n",
            "Party 2: efefewf\n",
            "Effective Date (YYYY-MM-DD): wefewfewf\n",
            "Terms and Conditions: weeffwewef\n",
            "Generated Contract: Below is a simplified contract template based on the general details you provided. Without specific details about the nature of the contract, I will present a generic agreement. You can modify it as necessary to suit the particular agreement being established.\n",
            "\n",
            "---\n",
            "\n",
            "**CONTRACT AGREEMENT**\n",
            "\n",
            "This Contract Agreement (\"Agreement\") is made on [Effective Date], by and between:\n",
            "\n",
            "**[Party A Name]**, with a principal place of business located at [Party A Address] (\"Party A\"),\n",
            "\n",
            "and\n",
            "\n",
            "**[Party B Name]**, with a principal place of business located at [Party B Address] (\"Party B\").\n",
            "\n",
            "**WHEREAS**, Party A and Party B (together, the \"Parties\") wish to outline the terms and conditions under which they will engage in [Brief Description of the Business Relationship or Transaction],\n",
            "\n",
            "**NOW, THEREFORE**, in consideration of the mutual covenants and promises herein contained, the Parties hereto agree as follows:\n",
            "\n",
            "1. **Scope of Work**\n",
            "   - Party A shall [describe duties, responsibilities, services provided, goods supplied, etc.],\n",
            "   - Party B shall [describe reciprocal duties, payment terms, delivery schedules etc.].\n",
            "\n",
            "2. **Term**\n",
            "   This Agreement shall commence on the effective date noted above and shall continue in effect until [Specify End Date or Event e.g., one year from the date hereof, completion of the specified work, etc.] unless earlier terminated by either party in accordance with the termination provisions below.\n",
            "\n",
            "3. **Payment Terms**\n",
            "   Party B agrees to compensate Party A [specify payment amount and schedule, e.g., $1,000 upon completion, $500 monthly, etc.].\n",
            "\n",
            "4. **Confidentiality**\n",
            "   During the term of this Agreement and thereafter, both parties agree to use reasonable diligence to keep all confidential information confidential, and not to disclose any confidential information to any third party without prior written consent.\n",
            "\n",
            "5. **Termination**\n",
            "   This Agreement may be terminated by either party upon [number] days’ written notice to the other party.\n",
            "\n",
            "6. **Dispute Resolution**\n",
            "   Any disputes arising out of or related to this Agreement shall be resolved by [mediation/arbitration/litigation] in [Location].\n",
            "\n",
            "7. **Miscellaneous**\n",
            "   - This Agreement constitutes the entire agreement between the parties.\n",
            "   - Any amendments to this Agreement must be written and signed by both parties.\n",
            "   - This Agreement is governed by the laws of [Specify State or Country].\n",
            "\n",
            "IN WITNESS WHEREOF, the parties hereto have executed this Contract Agreement as of the Effective Date.\n",
            "\n",
            "**Party A Signature:** ___________________________________\n",
            "\n",
            "**[Printed Name of Party A]**\n",
            "\n",
            "**Party B Signature:** ___________________________________\n",
            "\n",
            "**[Printed Name of Party B]**\n",
            "\n",
            "---\n",
            "\n",
            "Please ensure that you adapt the document to include specific details pertinent to the transaction or relationship it is intended to govern, and consider having a legal professional review it for completeness and compliance with local laws.\n",
            "Contract has been generated and saved as generated_contract.docx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3FEKFeuSVm64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans"
      ],
      "metadata": {
        "id": "qOI7vWtKKmvv",
        "outputId": "da6dd533-4116-45cb-db40-9251dcc6362e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from docx import Document\n",
        "import io\n",
        "from openai import OpenAI\n",
        "\n",
        "class NaturalLanguageComplianceChecker:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,  # Replace with actual URL including http:// or https://\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r', errors=\"ignore\") as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents for legal validation\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def validate_contract(self, contract_text):\n",
        "        relevant_docs = self.retrieve_relevant_documents(\"contract clause compliance\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Validate the following contract content for legal compliance:\n",
        "\n",
        "        Contract Text: {contract_text}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance validation and suggestions:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal compliance assistant specializing in Indian law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "def upload_contract_file():\n",
        "    uploaded = files.upload()\n",
        "    filename = next(iter(uploaded))\n",
        "\n",
        "    # Read the uploaded .docx file\n",
        "    with io.BytesIO(uploaded[filename]) as file:\n",
        "        doc = Document(file)\n",
        "        contract_text = '\\n'.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    return contract_text\n",
        "\n",
        "def main():\n",
        "    # Initialize the compliance checker agent\n",
        "    agent = NaturalLanguageComplianceChecker(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    # Step 1: Upload a file from Colab\n",
        "    print(\"Please upload your contract file:\")\n",
        "    contract_text = upload_contract_file()\n",
        "\n",
        "    # Step 2: Validate the contract content and provide suggestions\n",
        "    validation_result = agent.validate_contract(contract_text)\n",
        "    print(f\"\\nCompliance Validation and Suggestions:\\n{validation_result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "t9RF-jTGEO8e",
        "outputId": "e91c797f-05cb-431f-ee2b-fb1f5ac98873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'BaseTransport' from 'httpx' (/usr/local/lib/python3.10/dist-packages/httpx/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-435105dc11fb>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdocx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNaturalLanguageComplianceChecker\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotGiven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxiesTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/batch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_error\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_request_counts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchRequestCounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfields\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFieldInfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m from ._types import (\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mBody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mIncEx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydantic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhttpx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mURL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAsyncBaseTransport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseTransport' from 'httpx' (/usr/local/lib/python3.10/dist-packages/httpx/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rv0tIo64R46S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}