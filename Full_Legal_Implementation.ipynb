{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush834/AusgutAI/blob/main/Full_Legal_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6jseLEgVhC3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai portkey-ai transformers torch sentence-transformers scikit-learn numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "054Rd2MfOxzg",
        "outputId": "cea9d182-df56-4e97-d3a6-3af1b64ce2ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting portkey-ai\n",
            "  Downloading portkey_ai-1.8.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting mypy<2.0,>=0.991 (from portkey-ai)\n",
            "  Downloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting cached-property (from portkey-ai)\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting types-requests (from portkey-ai)\n",
            "  Downloading types_requests-2.32.0.20240907-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy<2.0,>=0.991->portkey-ai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy<2.0,>=0.991->portkey-ai) (2.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portkey_ai-1.8.7-py3-none-any.whl (460 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.9/460.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading types_requests-2.32.0.20240907-py3-none-any.whl (15 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cached-property, types-requests, mypy-extensions, jiter, h11, mypy, httpcore, httpx, portkey-ai, openai, sentence-transformers\n",
            "Successfully installed cached-property-1.5.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 mypy-1.11.2 mypy-extensions-1.0.0 openai-1.44.0 portkey-ai-1.8.7 sentence-transformers-3.0.1 types-requests-2.32.0.20240907\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yj8Y2fqGzZwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class IndianLawRAGAgent:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def answer_legal_question(self, question, context):\n",
        "        inputs = self.bert_tokenizer(question, context, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(**inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_legal_advice(self, startup_type, situation):\n",
        "        relevant_docs = self.retrieve_relevant_documents(f\"{startup_type} {situation}\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"As a legal expert, provide advice for an Indian {startup_type} startup in the following situation: {situation}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Advice:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian startup law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize_law(self, law_name):\n",
        "        relevant_docs = self.retrieve_relevant_documents(law_name)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Summarize the key points of the Indian law: {law_name}, especially as it pertains to startups.\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian law summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def check_compliance(self, startup_description):\n",
        "        relevant_docs = self.retrieve_relevant_documents(startup_description)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Given the following Indian startup description, list the key compliance requirements and potential legal issues to be aware of: {startup_description}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance requirements and potential legal issues:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in compliance for Indian startups.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "def main():\n",
        "    agent = IndianLawRAGAgent(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    print(\"Choose an option:\")\n",
        "    print(\"1. Answer a legal question\")\n",
        "    print(\"2. Generate legal advice\")\n",
        "    print(\"3. Summarize a law\")\n",
        "    print(\"4. Check compliance requirements\")\n",
        "\n",
        "    choice = int(input(\"Enter the number of your choice: \"))\n",
        "\n",
        "    if choice == 1:\n",
        "        legal_question = input(\"Enter your legal question: \")\n",
        "        legal_context = input(\"Enter the legal context: \")\n",
        "        answer = agent.answer_legal_question(legal_question, legal_context)\n",
        "        print(f\"Answer: {answer}\")\n",
        "\n",
        "    elif choice == 2:\n",
        "        startup_type = input(\"Enter the startup type: \")\n",
        "        situation = input(\"Describe the situation: \")\n",
        "        advice = agent.generate_legal_advice(startup_type, situation)\n",
        "        print(f\"Legal Advice: {advice}\")\n",
        "\n",
        "    elif choice == 3:\n",
        "        law_name = input(\"Enter the law name: \")\n",
        "        summary = agent.summarize_law(law_name)\n",
        "        print(f\"Law Summary: {summary}\")\n",
        "\n",
        "    elif choice == 4:\n",
        "        startup_description = input(\"Enter the startup description: \")\n",
        "        compliance = agent.check_compliance(startup_description)\n",
        "        print(f\"Compliance Check: {compliance}\")\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "alD8NUb3-uMJ",
        "outputId": "262d19a7-96c7-46e0-e57f-0cc80e8b2d26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentence_transformers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-577297a29a7a>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mportkey_ai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreateHeaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPORTKEY_GATEWAY_URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class IndianLawRAGAgent:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def answer_legal_question(self, question, context):\n",
        "        inputs = self.bert_tokenizer(question, context, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_legal_advice(self, startup_type, situation):\n",
        "        relevant_docs = self.retrieve_relevant_documents(f\"{startup_type} {situation}\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"As a legal expert, provide advice for an Indian {startup_type} startup in the following situation: {situation}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Advice:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian startup law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize_law(self, law_name):\n",
        "        relevant_docs = self.retrieve_relevant_documents(law_name)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Summarize the key points of the Indian law: {law_name}, especially as it pertains to startups.\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian law summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def check_compliance(self, startup_description):\n",
        "        relevant_docs = self.retrieve_relevant_documents(startup_description)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Given the following Indian startup description, list the key compliance requirements and potential legal issues to be aware of: {startup_description}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance requirements and potential legal issues:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in compliance for Indian startups.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def handle_user_input(self, user_input):\n",
        "        # Step 1: Summarize the user input\n",
        "        summarization_prompt = f\"\"\"Summarize the following legal input to extract key points:\n",
        "\n",
        "        Input: {user_input}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        summarization_response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI summarization assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": summarization_prompt}\n",
        "            ]\n",
        "        )\n",
        "        summarized_input = summarization_response.choices[0].message.content.strip()\n",
        "        print(f\"Summarized Input: {summarized_input}\")\n",
        "\n",
        "        # Step 2: Classify the user input into a type (e.g., 'legal question', 'generate advice', etc.)\n",
        "        classification_prompt = f\"\"\"Classify the following summarized legal input into one of these categories:\n",
        "        'legal question', 'generate advice', 'summarize law', 'check compliance'.\n",
        "\n",
        "        Summary: {summarized_input}\n",
        "\n",
        "        Classification:\"\"\"\n",
        "\n",
        "        classification_response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI classification assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": classification_prompt}\n",
        "            ]\n",
        "        )\n",
        "        classification = classification_response.choices[0].message.content.strip().lower()\n",
        "        print(f\"Classification: {classification}\")\n",
        "\n",
        "        # Step 3: Based on classification, automatically generate the legal context or invoke appropriate function\n",
        "        if \"legal question\" in classification:\n",
        "            # Use OpenAI to generate the legal context automatically\n",
        "            legal_context_prompt = f\"\"\"Generate the legal context for the following legal question:\n",
        "\n",
        "            Question: {summarized_input}\n",
        "\n",
        "            Legal Context:\"\"\"\n",
        "\n",
        "            legal_context_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an AI legal context assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": legal_context_prompt}\n",
        "                ]\n",
        "            )\n",
        "            legal_context = legal_context_response.choices[0].message.content.strip()\n",
        "            print(f\"Legal Context: {legal_context}\")\n",
        "            return f\"Function called: answer_legal_question\\nResponse: {self.answer_legal_question(summarized_input, legal_context)}\"\n",
        "\n",
        "        elif \"generate advice\" in classification:\n",
        "            # Auto-generate startup type based on the input (if applicable)\n",
        "            startup_type_prompt = f\"\"\"Identify the startup type based on the following input:\n",
        "\n",
        "            Input: {summarized_input}\n",
        "\n",
        "            Startup Type:\"\"\"\n",
        "\n",
        "            startup_type_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an AI startup classification assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": startup_type_prompt}\n",
        "                ]\n",
        "            )\n",
        "            startup_type = startup_type_response.choices[0].message.content.strip()\n",
        "            print(f\"Startup Type: {startup_type}\")\n",
        "            return f\"Function called: generate_legal_advice\\nResponse: {self.generate_legal_advice(startup_type, summarized_input)}\"\n",
        "\n",
        "        elif \"summarize law\" in classification:\n",
        "            return f\"Function called: summarize_law\\nResponse: {self.summarize_law(summarized_input)}\"\n",
        "\n",
        "        elif \"check compliance\" in classification:\n",
        "            return f\"Function called: check_compliance\\nResponse: {self.check_compliance(summarized_input)}\"\n",
        "\n",
        "        else:\n",
        "            return \"Sorry, I couldn't classify your input. Please try again.\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    agent = IndianLawRAGAgent(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    user_input = input(\"Enter your request: \")\n",
        "    response = agent.handle_user_input(user_input)\n",
        "    print(f\"Response: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "9yLbuIrioLaX",
        "outputId": "76ab6029-7c83-481a-cdfd-9d89e828a01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your request: startup at health\n",
            "Summarized Input: The input \"startup at health\" is quite brief and lacks specific details, making it difficult to provide a detailed summary. It generally suggests a focus on a startup company operating within the healthcare sector. Further information about the company's activities, objectives, or context would be required to offer a more precise summary.\n",
            "Classification: summarize law\n",
            "Response: Function called: summarize_law\n",
            "Response: The Indian legal framework provides a structured process for setting up a business, including health sector startups. Here are the main points concerning the legal formalities for starting a company in India, especially relevant for startups like those in healthcare:\n",
            "\n",
            "1. **Company Registration**: All new businesses must register with the Registrar of Companies (RoC). Essential steps include selecting a suitable company name, acquiring a Digital Signature Certificate (DSC), and filing the necessary incorporation documents.\n",
            "\n",
            "2. **Types of Companies**: Prospective entrepreneurs can choose from several types of company structures depending on their needs, including a Private Limited Company, Public Limited Company, and Limited Liability Partnership (LLP). Each type offers different benefits and limitations concerning liability, the number of stakeholders, capital requirements, and compliance.\n",
            "\n",
            "3. **Digital Signature Certificate (DSC)**: A DSC is mandatory for filing electronic submissions with the RoC. This ensures the security and authenticity of the documents filed.\n",
            "\n",
            "4. **Compliance and Regulations**: Post-registration, the company must adhere to various statutory compliances including tax registrations, obtaining necessary business licenses (especially critical in the healthcare sector for regulatory approvals), annual filings, and audits.\n",
            "\n",
            "These steps are essential to legally establish and operate a startup in the Indian healthcare sector, ensuring compliance with statutory obligations and smoothing the path for business operations and growth.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-docx"
      ],
      "metadata": {
        "id": "ggqsQz6PDUjR",
        "outputId": "8e546831-df1a-4365-ae7b-10507d883bff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KIeSzcmoEJ-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from docx import Document\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class ContractGenerator:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def extract_information_with_bert(self, text):\n",
        "        inputs = self.bert_tokenizer(text, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(**inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_contract(self, details):\n",
        "        # Use BERT to extract and refine contract details if necessary\n",
        "        refined_details = self.extract_information_with_bert(details)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Create a legal contract based on the following details:\n",
        "\n",
        "        Contract Details:\n",
        "        {refined_details}\n",
        "\n",
        "        The contract should include:\n",
        "        - Names of the parties\n",
        "        - Effective date\n",
        "        - Terms and conditions\n",
        "        - Signatures\n",
        "\n",
        "        Contract:\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a legal expert specializing in drafting contracts.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def save_contract_to_file(self, contract_text, filename=\"contract.docx\"):\n",
        "        doc = Document()\n",
        "        doc.add_paragraph(contract_text)\n",
        "        doc.add_paragraph(\"[It is advisable that both parties have this document reviewed by their respective legal advisors before signing.]\")\n",
        "        doc.save(filename)\n",
        "\n",
        "    def handle_user_request(self, contract_details):\n",
        "        # Generate contract text\n",
        "        contract_text = self.generate_contract(contract_details)\n",
        "        print(f\"Generated Contract: {contract_text}\")\n",
        "\n",
        "        # Save to file\n",
        "        filename = \"generated_contract.docx\"\n",
        "        self.save_contract_to_file(contract_text, filename)\n",
        "\n",
        "        return filename\n",
        "\n",
        "def main():\n",
        "    agent = ContractGenerator(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    # Collect contract details from the user\n",
        "    print(\"Please provide the following details for the contract:\")\n",
        "    party1 = input(\"Party 1: \")\n",
        "    party2 = input(\"Party 2: \")\n",
        "    effective_date = input(\"Effective Date (YYYY-MM-DD): \")\n",
        "    terms = input(\"Terms and Conditions: \")\n",
        "\n",
        "    contract_details = f\"\"\"\n",
        "    Party 1: {party1}\n",
        "    Party 2: {party2}\n",
        "    Effective Date: {effective_date}\n",
        "    Terms and Conditions: {terms}\n",
        "    \"\"\"\n",
        "\n",
        "    filename = agent.handle_user_request(contract_details)\n",
        "    print(f\"Contract has been generated and saved as {filename}.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "nPySUAVk3pql",
        "outputId": "75c5e303-4263-48a9-e207-aa84357c0ffd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide the following details for the contract:\n",
            "Party 1: Demo 1\n",
            "Party 2: Demo 2\n",
            "Effective Date (YYYY-MM-DD): 24-08-09\n",
            "Terms and Conditions: tets\n",
            "Generated Contract: Certainly! Below, you'll find a template for a simple legal contract based on the information provided. Please note that specific details such as the nature of the agreement, considerations, obligations, and detailed terms should be tailored to the specific agreement between the parties. This template provides a generic framework that should be adapted to the specific context of the contract.\n",
            "\n",
            "---\n",
            "\n",
            "**CONTRACT AGREEMENT**\n",
            "\n",
            "This Contract Agreement (the \"Agreement\") is entered into as of [Date], (\"Effective Date\"), by and between [Party A Name], with a principal place of business located at [Party A Address] (\"Party A\"), and [Party B Name], with a principal place of business located at [Party B Address] (\"Party B\").\n",
            "\n",
            "**WHEREAS**, Party A and Party B wish to establish the terms and conditions under which they will conduct [describe the purpose of the contract or relationship, e.g., sale of goods, provision of services, etc.];\n",
            "\n",
            "**NOW, THEREFORE**, in consideration of the mutual covenants and promises herein contained, the parties hereto agree as follows:\n",
            "\n",
            "1. **Scope of Work**\n",
            "   - [Describe the obligations or services to be provided. Be specific about the deliverables, timeframes, and requirements.]\n",
            "\n",
            "2. **Payment Terms**\n",
            "   - [Detail payment intervals, amounts, methods of payment, and any contingencies payment is based upon.]\n",
            "\n",
            "3. **Confidentiality**\n",
            "   - Each party agrees to maintain the confidentiality of all proprietary information received from the other party during the course of this Agreement and to use such information only as expressly permitted under the terms of this Agreement.\n",
            "\n",
            "4. **Term and Termination**\n",
            "   - This Agreement shall commence on the Effective Date and shall continue until [insert termination conditions, e.g., a specific date, completion of obligations, etc.]. Either party may terminate the Agreement with a written notice of [insert number of days] days.\n",
            "\n",
            "5. **Liability and Indemnification**\n",
            "   - Each party shall be responsible for any losses or damages caused by them or their representatives in connection with the performance of this Agreement and agrees to indemnify and hold harmless the other from any claims, including legal fees, arising from such damages.\n",
            "\n",
            "6. **Dispute Resolution**\n",
            "   - The parties agree that any disputes arising out of or related to this Agreement shall be resolved through [mediation/arbitration] before resorting to litigation.\n",
            "\n",
            "7. **Force Majeure**\n",
            "   - Neither party shall be liable for any failure to perform its obligations under this Agreement if such failure is caused by unforeseen circumstances beyond reasonable control of the parties, including but not limited to acts of God, war, or natural disaster.\n",
            "\n",
            "8. **Miscellaneous**\n",
            "   - This Agreement represents the entire agreement between the parties hereto and supersedes all prior discussions, agreements, or understandings of any kind. This Agreement may be amended only by written agreement signed by all parties.\n",
            "\n",
            "IN WITNESS WHEREOF, the parties hereto have executed this Contract Agreement as of the day and year first above written.\n",
            "\n",
            "[Party A Name]  \n",
            "Signature: ___________________________  \n",
            "Name: [Print Name]  \n",
            "Title: [Title]  \n",
            "Date: ____________________  \n",
            "\n",
            "[Party B Name]  \n",
            "Signature: ___________________________  \n",
            "Name: [Print Name]  \n",
            "Title: [Title]  \n",
            "Date: ____________________  \n",
            "\n",
            "---\n",
            "\n",
            "Be sure to consult an attorney to tailor the contract specifically to the circumstances and ensure that all legal aspects are properly covered according to local laws and regulations.\n",
            "Contract has been generated and saved as generated_contract.docx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3FEKFeuSVm64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install googletrans"
      ],
      "metadata": {
        "id": "qOI7vWtKKmvv",
        "outputId": "da6dd533-4116-45cb-db40-9251dcc6362e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.8.30)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from docx import Document\n",
        "import io\n",
        "from openai import OpenAI\n",
        "\n",
        "class NaturalLanguageComplianceChecker:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,  # Replace with actual URL including http:// or https://\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r', errors=\"ignore\") as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents for legal validation\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def validate_contract(self, contract_text):\n",
        "        relevant_docs = self.retrieve_relevant_documents(\"contract clause compliance\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Validate the following contract content for legal compliance:\n",
        "\n",
        "        Contract Text: {contract_text}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance validation and suggestions:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal compliance assistant specializing in Indian law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "def upload_contract_file():\n",
        "    uploaded = files.upload()\n",
        "    filename = next(iter(uploaded))\n",
        "\n",
        "    # Read the uploaded .docx file\n",
        "    with io.BytesIO(uploaded[filename]) as file:\n",
        "        doc = Document(file)\n",
        "        contract_text = '\\n'.join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    return contract_text\n",
        "\n",
        "def main():\n",
        "    # Initialize the compliance checker agent\n",
        "    agent = NaturalLanguageComplianceChecker(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    # Step 1: Upload a file from Colab\n",
        "    print(\"Please upload your contract file:\")\n",
        "    contract_text = upload_contract_file()\n",
        "\n",
        "    # Step 2: Validate the contract content and provide suggestions\n",
        "    validation_result = agent.validate_contract(contract_text)\n",
        "    print(f\"\\nCompliance Validation and Suggestions:\\n{validation_result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "t9RF-jTGEO8e",
        "outputId": "91e55551-46ce-46c2-9895-2bb5a7483a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your contract file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b055f830-c7d4-4a3e-9f55-3e4413eea439\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b055f830-c7d4-4a3e-9f55-3e4413eea439\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving generated_contract(1).docx to generated_contract(1).docx\n",
            "\n",
            "Compliance Validation and Suggestions:\n",
            "### Compliance Validation and Suggestions:\n",
            "The contract content provided is generally comprehensive and outlines the key aspects of a service agreement contract. However, there are a few areas where it can be improved to ensure better legal compliance and clarity under Indian law:\n",
            "\n",
            "1. **Jurisdiction and Governing Law**:\n",
            "   - The clause about governing law mentions \"the laws of the state of **[State]**.\" It should explicitly specify that the agreement is governed by Indian laws to avoid any ambiguity considering the multi-jurisdictional nature of Indian states.\n",
            "   - Example amendment: \"This Agreement shall be governed by and construed in accordance with the laws of India.\"\n",
            "\n",
            "2. **Scope of Services (Article 1)**:\n",
            "   - The services need to be described precisely in the agreement. Vague descriptions could lead to disputes regarding the scope of work. It is beneficial to detail the services to avoid misunderstandings or unrealistic expectations.\n",
            "\n",
            "3. **Payment Terms (Article 2)**:\n",
            "   - It is necessary to include more detailed payment terms including the modes of payment (cheques, bank transfers, etc.), and any advance payment or security deposit requirements.\n",
            "   - Including a provision concerning the applicability of GST (Goods and Services Tax) and mentioning who bears the tax liabilities would align it with Indian tax regulations.\n",
            "   - Example for taxes: \"All payments stated herein are exclusive of all taxes, GST, duties, fees, levies or other charges imposed by any governmental authority on the services rendered under this agreement.\"\n",
            "\n",
            "4. **Confidentiality (Article 4)**:\n",
            "   - This section can be broadened to define what constitutes confidential information more clearly. This can include business methods, strategies, and any other data not publicly available.\n",
            "   - A clause might also be added to discuss the return or destruction of confidential material upon termination of the agreement.\n",
            "\n",
            "5. **Liability and Indemnity (Article 5)**:\n",
            "   - Indian contracts typically include a detailed indemnity provision protecting both parties against losses arising from breaches of the contract or other liabilities. \n",
            "   - The exculpatory clause in 5.1 might not hold in cases where a loss is due to negligence or misconduct; hence the language should be adjusted to be compliant with Indian legal standards regarding negligence and professional liability.\n",
            "\n",
            "6. **Termination (Article 3)**:\n",
            "   - Specifying conditions under which the contract can be terminated by either party, apart from just a notice period, could be useful. This includes material breach, insolvency, or inability to perform the agreed services.\n",
            "   - Clarity on the rights and obligations post-termination concerning outstanding payments, return of property, and confidentiality would be prudent.\n",
            "\n",
            "7. **Dispute Resolution**:\n",
            "   - It can be helpful to include a dispute resolution mechanism, specifying how disputes will be resolved, whether through arbitration, mediation, or court proceedings. Specifying the venue (i.e., which city's courts) can also prevent jurisdictional disputes.\n",
            "\n",
            "8. **Signatures and Dates**:\n",
            "   - Ensure that the signatures are affixed and the dates of signing are indicated to validate the contract.\n",
            "\n",
            "By instituting these additions and clarifications, the contract will be better tailored to the specific needs of both parties while ensuring compliance with Indian legal standards and regulations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from docx import Document\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class ContractGenerator:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.company_name = data[\"company_name\"]\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def ask_contract_type(self):\n",
        "        print(\"Please select the type of contract you want to generate:\")\n",
        "        print(\"1. Employment Contract\")\n",
        "        print(\"2. Non-Disclosure Agreement (NDA)\")\n",
        "        print(\"3. Partnership Agreement\")\n",
        "        contract_type = input(\"Enter the number corresponding to the contract type: \")\n",
        "        return contract_type\n",
        "\n",
        "    def ask_general_questions(self):\n",
        "        employee_name = input(\"Enter the employee's full name: \")\n",
        "        start_date = input(\"Enter the contract start date (YYYY-MM-DD): \")\n",
        "        return employee_name, start_date\n",
        "\n",
        "    def ask_employment_contract_questions(self):\n",
        "        job_title = input(\"Enter the job title: \")\n",
        "        salary_info = input(\"Enter the salary information: \")\n",
        "        responsibilities = input(\"Enter key responsibilities: \")\n",
        "        return job_title, salary_info, responsibilities\n",
        "\n",
        "    def ask_nda_questions(self):\n",
        "        parties = input(\"Enter the names of the parties involved: \")\n",
        "        confidential_info = input(\"Enter a brief description of the confidential information: \")\n",
        "        return parties, confidential_info\n",
        "\n",
        "    def ask_partnership_agreement_questions(self):\n",
        "        partners = input(\"Enter the names of the partners: \")\n",
        "        partnership_terms = input(\"Enter the key terms of the partnership: \")\n",
        "        return partners, partnership_terms\n",
        "\n",
        "    def generate_contract_prompt(self, contract_type, details):\n",
        "        if contract_type == '1':  # Employment Contract\n",
        "            job_title, salary_info, responsibilities = details\n",
        "            prompt = f\"\"\"\n",
        "            Create a legal employment contract based on the following information:\n",
        "\n",
        "            Company: {self.company_name}\n",
        "            Job Title: {job_title}\n",
        "            Employee: {self.employee_name}\n",
        "            Start Date: {self.start_date}\n",
        "            Salary Information: {salary_info}\n",
        "            Key Responsibilities: {responsibilities}\n",
        "\n",
        "            The contract should include:\n",
        "            - Names of the parties\n",
        "            - Effective date\n",
        "            - Job title and department\n",
        "            - Salary and benefits\n",
        "            - Key responsibilities\n",
        "            - Standard work terms\n",
        "            - Signatures\n",
        "\n",
        "            Contract:\n",
        "            \"\"\"\n",
        "        elif contract_type == '2':  # NDA\n",
        "            parties, confidential_info = details\n",
        "            prompt = f\"\"\"\n",
        "            Create a Non-Disclosure Agreement (NDA) based on the following information:\n",
        "\n",
        "            Company: {self.company_name}\n",
        "            Parties: {parties}\n",
        "            Confidential Information: {confidential_info}\n",
        "\n",
        "            The NDA should include:\n",
        "            - Definition of confidential information\n",
        "            - Obligations of the parties\n",
        "            - Term and duration of the NDA\n",
        "            - Non-use and non-disclosure clauses\n",
        "            - Termination conditions\n",
        "            - Signatures\n",
        "\n",
        "            NDA:\n",
        "            \"\"\"\n",
        "        elif contract_type == '3':  # Partnership Agreement\n",
        "            partners, partnership_terms = details\n",
        "            prompt = f\"\"\"\n",
        "            Create a Partnership Agreement based on the following information:\n",
        "\n",
        "            Company: {self.company_name}\n",
        "            Partners: {partners}\n",
        "            Key Terms: {partnership_terms}\n",
        "\n",
        "            The agreement should include:\n",
        "            - Names of the parties\n",
        "            - Partnership terms\n",
        "            - Responsibilities of the partners\n",
        "            - Profit and loss sharing terms\n",
        "            - Dispute resolution\n",
        "            - Termination conditions\n",
        "            - Signatures\n",
        "\n",
        "            Partnership Agreement:\n",
        "            \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def generate_contract(self, contract_type):\n",
        "        if contract_type == '1':  # Employment Contract\n",
        "            details = self.ask_employment_contract_questions()\n",
        "        elif contract_type == '2':  # NDA\n",
        "            details = self.ask_nda_questions()\n",
        "        elif contract_type == '3':  # Partnership Agreement\n",
        "            details = self.ask_partnership_agreement_questions()\n",
        "        else:\n",
        "            print(\"Invalid contract type selected.\")\n",
        "            return None\n",
        "\n",
        "        # Combine general questions (employee name, start date, etc.)\n",
        "        self.employee_name, self.start_date = self.ask_general_questions()\n",
        "        prompt = self.generate_contract_prompt(contract_type, details)\n",
        "\n",
        "        # Use OpenAI to generate the contract text\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a legal expert specializing in drafting contracts.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def save_contract_to_file(self, contract_text, filename=\"contract.docx\"):\n",
        "        doc = Document()\n",
        "        doc.add_paragraph(contract_text)\n",
        "        doc.add_paragraph(\"[It is advisable that both parties have this document reviewed by their respective legal advisors before signing.]\")\n",
        "        doc.save(filename)\n",
        "\n",
        "    def generate_and_save_contract(self):\n",
        "        contract_type = self.ask_contract_type()\n",
        "        contract_text = self.generate_contract(contract_type)\n",
        "        if contract_text:\n",
        "            print(f\"\\nGenerated Contract:\\n\\n{contract_text}\\n\")\n",
        "\n",
        "            # Save to file\n",
        "            filename = f\"generated_{self.company_name.replace(' ', '').lower()}_contract_{contract_type}.docx\"\n",
        "            self.save_contract_to_file(contract_text, filename)\n",
        "\n",
        "            print(f\"Contract has been generated and saved as {filename}.\")\n",
        "\n",
        "def main():\n",
        "    agent = ContractGenerator(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "    agent.generate_and_save_contract()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "rv0tIo64R46S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9018f935-fa94-4c9d-8be4-08b1b278eb23"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please select the type of contract you want to generate:\n",
            "1. Employment Contract\n",
            "2. Non-Disclosure Agreement (NDA)\n",
            "3. Partnership Agreement\n",
            "Enter the number corresponding to the contract type: 2\n",
            "Enter the names of the parties involved: 2\n",
            "Enter a brief description of the confidential information: test\n",
            "Enter the employee's full name: bhbhb\n",
            "Enter the contract start date (YYYY-MM-DD): h87879y87g\n",
            "\n",
            "Generated Contract:\n",
            "\n",
            "**NON-DISCLOSURE AGREEMENT**\n",
            "\n",
            "This Non-Disclosure Agreement (\"Agreement\") is entered into as of [Date] by and between TechNova Solutions Pvt. Ltd., a private limited company incorporated and existing under the laws of [Jurisdiction of Incorporation] with its principal office at [Address] (\"Disclosing Party\"), and [Other Party Name], a [Describe Entity Type - e.g., corporation, individual, etc.] organized and existing under the laws of [Jurisdiction of Incorporation] with its principal office at [Address] (\"Receiving Party\") (collectively referred to as the \"Parties\").\n",
            "\n",
            "**1. Definition of Confidential Information**\n",
            "For purposes of this Agreement, \"Confidential Information\" includes all written, electronic, or oral information that the Disclosing Party provides to the Receiving Party, including but not limited to technical, commercial, financial, employee, planning, and business information, strategies, rankings, and methodologies, explicitly marked as “confidential” or reasonably identifiable as confidential based on the nature of the information and the circumstances surrounding its disclosure.\n",
            "\n",
            "**2. Obligations of the Parties**\n",
            "Each party agrees to:\n",
            "a. Hold and maintain the Confidential Information in strictest confidence for the sole and exclusive benefit of the Disclosing Party.\n",
            "b. Carefully restrict access to Confidential Information to employees, contractors, and third parties as is reasonably required and only disclose to such employees, contractors, and third parties who have signed nondisclosure restrictions at least as protective as those in this Agreement.\n",
            "c. Not use the Confidential Information for any purpose except for evaluating or pursuing a business relationship directly related to the agreement.\n",
            "d. Not disclose any Confidential Information received under this Agreement to any party without the prior written consent of the Disclosing Party.\n",
            "\n",
            "**3. Term and Duration**\n",
            "This Agreement shall commence on the date written above and shall continue in effect until the Confidential Information no longer qualifies as confidential or until terminated by either party with thirty (30) days written notice to the other party.\n",
            "\n",
            "**4. Non-use and Non-disclosure**\n",
            "The Receiving Party shall not, during the term of this Agreement and for a period of five (5) years after its termination:\n",
            "a. Use the Confidential Information except as necessary for performing the obligations under this Agreement.\n",
            "b. Disclose any Confidential Information to any third party, except as may be necessary and required in connection with the rights and obligations under this Agreement and subject to confidentiality obligations at least as protective as those contained herein.\n",
            "\n",
            "**5. Termination Conditions**\n",
            "This Agreement may be terminated:\n",
            "a. By either party upon thirty (30) days written notice to the other party.\n",
            "b. Automatically, upon the conclusion of business dealings between the parties or if the project or purpose for which the Confidential Information was disclosed is completed or abandoned.\n",
            "\n",
            "**6. Return of Materials**\n",
            "Upon termination of this Agreement, the Receiving Party agrees to return all documents, notes, and other tangible materials representing the Confidential Information and all copies thereof, or to certify in writing that all such materials have been destroyed.\n",
            "\n",
            "**7. Signatures**\n",
            "Each party represents and warrants that its respective signatories whose signatures are set forth below are duly authorized to execute this Agreement.\n",
            "\n",
            "IN WITNESS WHEREOF, the parties hereto have executed this Non-Disclosure Agreement on the day and year first above written.\n",
            "\n",
            "/s/ [Signature]\n",
            "Name:\n",
            "Title:\n",
            "TechNova Solutions Pvt. Ltd.\n",
            "\n",
            "/s/ [Signature]\n",
            "Name:\n",
            "Title:\n",
            "[Other Party Name]\n",
            "\n",
            "[Information within brackets [] should be completed or adjusted to the specifics of the parties and context of the confidentiality.]\n",
            "\n",
            "Contract has been generated and saved as generated_technovasolutionspvt.ltd._contract_2.docx.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QmzZIO05hISQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}