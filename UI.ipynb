{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFQc7buaajJcTJWj4ld//h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush834/AusgutAI/blob/main/UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zejns-efBifW",
        "outputId": "191b27f6-931a-498c-a9b1-6e6a34d64503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting portkey-ai\n",
            "  Downloading portkey_ai-1.8.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.43.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Collecting mypy<2.0,>=0.991 (from portkey-ai)\n",
            "  Downloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting cached-property (from portkey-ai)\n",
            "  Downloading cached_property-1.5.2-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting types-requests (from portkey-ai)\n",
            "  Downloading types_requests-2.32.0.20240907-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting fastapi<0.113.0 (from gradio)\n",
            "  Downloading fastapi-0.112.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m380.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<0.113.0->gradio)\n",
            "  Downloading starlette-0.38.4-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Collecting mypy-extensions>=1.0.0 (from mypy<2.0,>=0.991->portkey-ai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from mypy<2.0,>=0.991->portkey-ai) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portkey_ai-1.8.7-py3-none-any.whl (460 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.9/460.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.43.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.112.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading types_requests-2.32.0.20240907-py3-none-any.whl (15 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading starlette-0.38.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, cached-property, websockets, types-requests, tomlkit, semantic-version, ruff, python-multipart, orjson, mypy-extensions, jiter, h11, ffmpy, aiofiles, uvicorn, starlette, mypy, httpcore, httpx, fastapi, portkey-ai, openai, gradio-client, sentence-transformers, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "Successfully installed aiofiles-23.2.1 cached-property-1.5.2 fastapi-0.112.4 ffmpy-0.4.0 gradio-4.43.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 mypy-1.11.2 mypy-extensions-1.0.0 openai-1.44.0 orjson-3.10.7 portkey-ai-1.8.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.4 semantic-version-2.10.0 sentence-transformers-3.0.1 starlette-0.38.4 tomlkit-0.12.0 types-requests-2.32.0.20240907 uvicorn-0.30.6 websockets-12.0\n"
          ]
        }
      ],
      "source": [
        "pip install openai portkey-ai transformers torch sentence-transformers scikit-learn numpy gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import json\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class IndianLawRAGAgent:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def answer_legal_question(self, question, context):\n",
        "        inputs = self.bert_tokenizer(question, context, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(**inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_legal_advice(self, startup_type, situation):\n",
        "        relevant_docs = self.retrieve_relevant_documents(f\"{startup_type} {situation}\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"As a legal expert, provide advice for an Indian {startup_type} startup in the following situation: {situation}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Advice:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian startup law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize_law(self, law_name):\n",
        "        relevant_docs = self.retrieve_relevant_documents(law_name)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Summarize the key points of the Indian law: {law_name}, especially as it pertains to startups.\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian law summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def check_compliance(self, startup_description):\n",
        "        relevant_docs = self.retrieve_relevant_documents(startup_description)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Given the following Indian startup description, list the key compliance requirements and potential legal issues to be aware of: {startup_description}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance requirements and potential legal issues:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in compliance for Indian startups.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "def create_ui():\n",
        "    agent = IndianLawRAGAgent(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    def legal_question_interface(question, context):\n",
        "        return agent.answer_legal_question(question, context)\n",
        "\n",
        "    def legal_advice_interface(startup_type, situation):\n",
        "        return agent.generate_legal_advice(startup_type, situation)\n",
        "\n",
        "    def law_summary_interface(law_name):\n",
        "        return agent.summarize_law(law_name)\n",
        "\n",
        "    def compliance_check_interface(startup_description):\n",
        "        return agent.check_compliance(startup_description)\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# Indian Law RAG Agent\")\n",
        "\n",
        "        with gr.Tab(\"Answer Legal Question\"):\n",
        "            question = gr.Textbox(label=\"Enter your legal question\")\n",
        "            context = gr.Textbox(label=\"Enter the legal context\")\n",
        "            answer_button = gr.Button(\"Get Answer\")\n",
        "            answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "            answer_button.click(legal_question_interface, inputs=[question, context], outputs=answer_output)\n",
        "\n",
        "        with gr.Tab(\"Generate Legal Advice\"):\n",
        "            startup_type = gr.Textbox(label=\"Enter the startup type\")\n",
        "            situation = gr.Textbox(label=\"Describe the situation\")\n",
        "            advice_button = gr.Button(\"Get Advice\")\n",
        "            advice_output = gr.Textbox(label=\"Legal Advice\", interactive=False)\n",
        "            advice_button.click(legal_advice_interface, inputs=[startup_type, situation], outputs=advice_output)\n",
        "\n",
        "        with gr.Tab(\"Summarize Law\"):\n",
        "            law_name = gr.Textbox(label=\"Enter the law name\")\n",
        "            summary_button = gr.Button(\"Get Summary\")\n",
        "            summary_output = gr.Textbox(label=\"Law Summary\", interactive=False)\n",
        "            summary_button.click(law_summary_interface, inputs=[law_name], outputs=summary_output)\n",
        "\n",
        "        with gr.Tab(\"Check Compliance\"):\n",
        "            startup_description = gr.Textbox(label=\"Enter the startup description\")\n",
        "            compliance_button = gr.Button(\"Check Compliance\")\n",
        "            compliance_output = gr.Textbox(label=\"Compliance Check\", interactive=False)\n",
        "            compliance_button.click(compliance_check_interface, inputs=[startup_description], outputs=compliance_output)\n",
        "\n",
        "    demo.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_ui()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "qz7ZPE6mB1a2",
        "outputId": "ec27f11b-3cea-4850-c707-6a01103cea85"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://32b5291f3c348ddef0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://32b5291f3c348ddef0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from openai import OpenAI\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class IndianLawRAGAgent:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def answer_legal_question(self, question, context):\n",
        "        inputs = self.bert_tokenizer(question, context, return_tensors=\"pt\")\n",
        "        outputs = self.bert_model(**inputs)\n",
        "\n",
        "        answer_start = outputs.start_logits.argmax()\n",
        "        answer_end = outputs.end_logits.argmax() + 1\n",
        "        answer = self.bert_tokenizer.convert_tokens_to_string(\n",
        "            self.bert_tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
        "        )\n",
        "        return answer\n",
        "\n",
        "    def generate_legal_advice(self, startup_type, situation):\n",
        "        relevant_docs = self.retrieve_relevant_documents(f\"{startup_type} {situation}\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"As a legal expert, provide advice for an Indian {startup_type} startup in the following situation: {situation}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Advice:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian startup law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def summarize_law(self, law_name):\n",
        "        relevant_docs = self.retrieve_relevant_documents(law_name)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Summarize the key points of the Indian law: {law_name}, especially as it pertains to startups.\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in Indian law summaries.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def check_compliance(self, startup_description):\n",
        "        relevant_docs = self.retrieve_relevant_documents(startup_description)\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Given the following Indian startup description, list the key compliance requirements and potential legal issues to be aware of: {startup_description}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance requirements and potential legal issues:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal assistant specializing in compliance for Indian startups.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def handle_user_input(self, user_input):\n",
        "        # Step 1: Summarize the user input\n",
        "        summarization_prompt = f\"\"\"Summarize the following legal input to extract key points:\n",
        "\n",
        "        Input: {user_input}\n",
        "\n",
        "        Summary:\"\"\"\n",
        "\n",
        "        summarization_response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI summarization assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": summarization_prompt}\n",
        "            ]\n",
        "        )\n",
        "        summarized_input = summarization_response.choices[0].message.content.strip()\n",
        "\n",
        "        # Step 2: Classify the user input into a type (e.g., 'legal question', 'generate advice', etc.)\n",
        "        classification_prompt = f\"\"\"Classify the following summarized legal input into one of these categories:\n",
        "        'legal question', 'generate advice', 'summarize law', 'check compliance'.\n",
        "\n",
        "        Summary: {summarized_input}\n",
        "\n",
        "        Classification:\"\"\"\n",
        "\n",
        "        classification_response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI classification assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": classification_prompt}\n",
        "            ]\n",
        "        )\n",
        "        classification = classification_response.choices[0].message.content.strip().lower()\n",
        "\n",
        "        # Step 3: Based on classification, automatically generate the legal context or invoke appropriate function\n",
        "        if \"legal question\" in classification:\n",
        "            legal_context_prompt = f\"\"\"Generate the legal context for the following legal question:\n",
        "\n",
        "            Question: {summarized_input}\n",
        "\n",
        "            Legal Context:\"\"\"\n",
        "\n",
        "            legal_context_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an AI legal context assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": legal_context_prompt}\n",
        "                ]\n",
        "            )\n",
        "            legal_context = legal_context_response.choices[0].message.content.strip()\n",
        "            return f\"Function called: answer_legal_question\\nResponse: {self.answer_legal_question(summarized_input, legal_context)}\"\n",
        "\n",
        "        elif \"generate advice\" in classification:\n",
        "            startup_type_prompt = f\"\"\"Identify the startup type based on the following input:\n",
        "\n",
        "            Input: {summarized_input}\n",
        "\n",
        "            Startup Type:\"\"\"\n",
        "\n",
        "            startup_type_response = self.client.chat.completions.create(\n",
        "                model=\"gpt-4-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are an AI startup classification assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": startup_type_prompt}\n",
        "                ]\n",
        "            )\n",
        "            startup_type = startup_type_response.choices[0].message.content.strip()\n",
        "            return f\"Function called: generate_legal_advice\\nResponse: {self.generate_legal_advice(startup_type, summarized_input)}\"\n",
        "\n",
        "        elif \"summarize law\" in classification:\n",
        "            return f\"Function called: summarize_law\\nResponse: {self.summarize_law(summarized_input)}\"\n",
        "\n",
        "        elif \"check compliance\" in classification:\n",
        "            return f\"Function called: check_compliance\\nResponse: {self.check_compliance(summarized_input)}\"\n",
        "\n",
        "        else:\n",
        "            return \"Sorry, I couldn't classify your input. Please try again.\"\n",
        "\n",
        "def gradio_interface():\n",
        "    agent = IndianLawRAGAgent(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    def process_input(user_input):\n",
        "        return agent.handle_user_input(user_input)\n",
        "\n",
        "    iface = gr.Interface(\n",
        "        fn=process_input,\n",
        "        inputs=\"text\",\n",
        "        outputs=\"text\",\n",
        "        title=\"Indian Law RAG Agent\",\n",
        "        description=\"Ask legal questions or get advice related to Indian startup laws.\",\n",
        "        examples=[\n",
        "            [\"How can I register a startup in India?\"],\n",
        "            [\"What are the compliance requirements for an IT startup?\"],\n",
        "            [\"Summarize the Indian contract law.\"],\n",
        "            [\"Check compliance for a new e-commerce startup.\"]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    iface.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "0PbW-j_wCOS0",
        "outputId": "d038c5a5-52f0-4519-e663-967f5738abf0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://b59fe4892221242287.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b59fe4892221242287.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install docx python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwJND_qMDiNF",
        "outputId": "ad9c71b9-0c66-4136-8836-dd26e2633227"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: docx in /usr/local/lib/python3.10/dist-packages (0.2.4)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from docx) (4.9.4)\n",
            "Requirement already satisfied: Pillow>=2.0 in /usr/local/lib/python3.10/dist-packages (from docx) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from docx import Document\n",
        "import io\n",
        "from openai import OpenAI\n",
        "\n",
        "class NaturalLanguageComplianceChecker:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,  # Replace with actual URL including http:// or https://\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r', errors=\"ignore\") as f:\n",
        "            data = json.load(f)\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents for legal validation\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def retrieve_relevant_documents(self, query, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([query])\n",
        "        similarities = cosine_similarity(query_embedding, self.document_embeddings)[0]\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        return [self.knowledge_base[i] for i in top_indices]\n",
        "\n",
        "    def validate_contract(self, contract_text):\n",
        "        relevant_docs = self.retrieve_relevant_documents(\"contract clause compliance\")\n",
        "        context = \"\\n\".join([doc['content'] for doc in relevant_docs])\n",
        "\n",
        "        prompt = f\"\"\"Validate the following contract content for legal compliance:\n",
        "\n",
        "        Contract Text: {contract_text}\n",
        "\n",
        "        Relevant legal information:\n",
        "        {context}\n",
        "\n",
        "        Compliance validation and suggestions:\"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI legal compliance assistant specializing in Indian law.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "def upload_contract_file(file):\n",
        "    # Read the uploaded .docx file\n",
        "    doc = Document(io.BytesIO(file))\n",
        "    contract_text = '\\n'.join([para.text for para in doc.paragraphs])\n",
        "    return contract_text\n",
        "\n",
        "def validate_uploaded_file(file):\n",
        "    agent = NaturalLanguageComplianceChecker(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    # Get the contract text from the uploaded file\n",
        "    contract_text = upload_contract_file(file)\n",
        "\n",
        "    # Validate the contract and return the compliance result\n",
        "    validation_result = agent.validate_contract(contract_text)\n",
        "    return validation_result\n",
        "\n",
        "# Define Gradio UI\n",
        "def gradio_interface():\n",
        "    interface = gr.Interface(\n",
        "        fn=validate_uploaded_file,\n",
        "        inputs=gr.File(type=\"binary\", label=\"Upload .docx Contract File\"),\n",
        "        outputs=gr.Textbox(label=\"Compliance Validation and Suggestions\"),\n",
        "        title=\"Contract Compliance Checker\",\n",
        "        description=\"Upload a contract file in .docx format to get legal compliance validation and suggestions.\"\n",
        "    )\n",
        "    interface.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "HgwyR981GHuy",
        "outputId": "3f704466-6840-4fc4-c7f9-87ff98be6e52"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://33a3bb4cf7e7bb67f8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://33a3bb4cf7e7bb67f8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from datetime import datetime, timedelta\n",
        "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "from docx import Document\n",
        "from portkey_ai import createHeaders, PORTKEY_GATEWAY_URL\n",
        "\n",
        "class ContractGenerator:\n",
        "    def __init__(self, portkey_api_key, portkey_virtual_key, bert_model_name, knowledge_base_path):\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"dummy\",\n",
        "            base_url=PORTKEY_GATEWAY_URL,\n",
        "            default_headers=createHeaders(\n",
        "                provider=\"openai\",\n",
        "                api_key=portkey_api_key,\n",
        "                virtual_key=portkey_virtual_key\n",
        "            )\n",
        "        )\n",
        "        # Load BERT model and tokenizer from Hugging Face\n",
        "        self.bert_model = AutoModelForQuestionAnswering.from_pretrained(bert_model_name)\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "        self.sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "        # Load knowledge base\n",
        "        with open(knowledge_base_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            self.company_name = data[\"company_name\"]\n",
        "            self.knowledge_base = data[\"knowledge_base\"]\n",
        "\n",
        "        # Encode documents\n",
        "        self.document_embeddings = self.sentence_model.encode([doc['content'] for doc in self.knowledge_base])\n",
        "\n",
        "    def generate_contract_prompt(self, contract_type, details):\n",
        "        if contract_type == '1':  # Employment Contract\n",
        "            job_title, salary_info, responsibilities = details\n",
        "            prompt = f\"\"\"\n",
        "            Create a legal employment contract based on the following information:\n",
        "\n",
        "            Company: {self.company_name}\n",
        "            Job Title: {job_title}\n",
        "            Employee: {self.employee_name}\n",
        "            Start Date: {self.start_date}\n",
        "            Salary Information: {salary_info}\n",
        "            Key Responsibilities: {responsibilities}\n",
        "\n",
        "            The contract should include:\n",
        "            - Names of the parties\n",
        "            - Effective date\n",
        "            - Job title and department\n",
        "            - Salary and benefits\n",
        "            - Key responsibilities\n",
        "            - Standard work terms\n",
        "            - Signatures\n",
        "\n",
        "            Contract:\n",
        "            \"\"\"\n",
        "        elif contract_type == '2':  # NDA\n",
        "            parties, confidential_info = details\n",
        "            prompt = f\"\"\"\n",
        "            Create a Non-Disclosure Agreement (NDA) based on the following information:\n",
        "\n",
        "            Company: {self.company_name}\n",
        "            Parties: {parties}\n",
        "            Confidential Information: {confidential_info}\n",
        "\n",
        "            The NDA should include:\n",
        "            - Definition of confidential information\n",
        "            - Obligations of the parties\n",
        "            - Term and duration of the NDA\n",
        "            - Non-use and non-disclosure clauses\n",
        "            - Termination conditions\n",
        "            - Signatures\n",
        "\n",
        "            NDA:\n",
        "            \"\"\"\n",
        "        elif contract_type == '3':  # Partnership Agreement\n",
        "            partners, partnership_terms = details\n",
        "            prompt = f\"\"\"\n",
        "            Create a Partnership Agreement based on the following information:\n",
        "\n",
        "            Company: {self.company_name}\n",
        "            Partners: {partners}\n",
        "            Key Terms: {partnership_terms}\n",
        "\n",
        "            The agreement should include:\n",
        "            - Names of the parties\n",
        "            - Partnership terms\n",
        "            - Responsibilities of the partners\n",
        "            - Profit and loss sharing terms\n",
        "            - Dispute resolution\n",
        "            - Termination conditions\n",
        "            - Signatures\n",
        "\n",
        "            Partnership Agreement:\n",
        "            \"\"\"\n",
        "        return prompt\n",
        "\n",
        "    def generate_contract(self, contract_type, details, employee_name, start_date):\n",
        "        # Store general questions\n",
        "        self.employee_name = employee_name\n",
        "        self.start_date = start_date\n",
        "\n",
        "        prompt = self.generate_contract_prompt(contract_type, details)\n",
        "\n",
        "        # Use OpenAI to generate the contract text\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-4-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a legal expert specializing in drafting contracts.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "\n",
        "    def save_contract_to_file(self, contract_text, filename=\"contract.docx\"):\n",
        "        doc = Document()\n",
        "        doc.add_paragraph(contract_text)\n",
        "        doc.add_paragraph(\"[It is advisable that both parties have this document reviewed by their respective legal advisors before signing.]\")\n",
        "        doc.save(filename)\n",
        "\n",
        "    def generate_and_save_contract(self, contract_type, details, employee_name, start_date):\n",
        "        contract_text = self.generate_contract(contract_type, details, employee_name, start_date)\n",
        "        if contract_text:\n",
        "            filename = f\"generated_{self.company_name.replace(' ', '').lower()}_contract_{contract_type}.docx\"\n",
        "            self.save_contract_to_file(contract_text, filename)\n",
        "            return contract_text, filename\n",
        "\n",
        "# Define Gradio UI\n",
        "def gradio_interface():\n",
        "    agent = ContractGenerator(\n",
        "        portkey_api_key=\"1+YM2sBEgaZWe45bMOq2huic1uyF\",\n",
        "        portkey_virtual_key=\"015-openai-40bada\",\n",
        "        bert_model_name=\"law-ai/InLegalBERT\",\n",
        "        knowledge_base_path=\"test.json\"\n",
        "    )\n",
        "\n",
        "    def handle_contract_generation(contract_type, employee_name, start_date, job_title, salary_info, responsibilities, parties, confidential_info, partners, partnership_terms):\n",
        "        if contract_type == '1':\n",
        "            details = (job_title, salary_info, responsibilities)\n",
        "        elif contract_type == '2':\n",
        "            details = (parties, confidential_info)\n",
        "        elif contract_type == '3':\n",
        "            details = (partners, partnership_terms)\n",
        "        else:\n",
        "            return \"Invalid contract type.\"\n",
        "\n",
        "        contract_text, filename = agent.generate_and_save_contract(contract_type, details, employee_name, start_date)\n",
        "        return contract_text, filename\n",
        "\n",
        "    contract_type_input = gr.Radio(choices=['1', '2', '3'], label=\"Select Contract Type\")  # Corrected here\n",
        "\n",
        "    employee_name_input = gr.Textbox(label=\"Employee Name (for Employment Contract)\")\n",
        "    start_date_input = gr.Textbox(label=\"Contract Start Date (YYYY-MM-DD)\")\n",
        "    job_title_input = gr.Textbox(label=\"Job Title (for Employment Contract)\")\n",
        "    salary_info_input = gr.Textbox(label=\"Salary Information (for Employment Contract)\")\n",
        "    responsibilities_input = gr.Textbox(label=\"Responsibilities (for Employment Contract)\")\n",
        "    parties_input = gr.Textbox(label=\"Parties (for NDA)\")\n",
        "    confidential_info_input = gr.Textbox(label=\"Confidential Information (for NDA)\")\n",
        "    partners_input = gr.Textbox(label=\"Partners (for Partnership Agreement)\")\n",
        "    partnership_terms_input = gr.Textbox(label=\"Partnership Terms (for Partnership Agreement)\")\n",
        "\n",
        "    # Create Gradio interface\n",
        "    interface = gr.Interface(\n",
        "        fn=handle_contract_generation,\n",
        "        inputs=[\n",
        "            contract_type_input,\n",
        "            employee_name_input,\n",
        "            start_date_input,\n",
        "            job_title_input,\n",
        "            salary_info_input,\n",
        "            responsibilities_input,\n",
        "            parties_input,\n",
        "            confidential_info_input,\n",
        "            partners_input,\n",
        "            partnership_terms_input\n",
        "        ],\n",
        "        outputs=[\"text\", \"file\"],\n",
        "        title=\"Contract Generator\",\n",
        "        description=\"Generate Employment Contracts, NDAs, and Partnership Agreements based on input data.\"\n",
        "    )\n",
        "\n",
        "    interface.launch()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gradio_interface()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "KUL9QAEzGPyt",
        "outputId": "7074f41a-3806-4e96-a732-7cf21879ff7d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at law-ai/InLegalBERT and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ce6d4170ab02ecf6ec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ce6d4170ab02ecf6ec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmnZzdtCHhtm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}